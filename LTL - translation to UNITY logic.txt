I thought you might be interested in knowing that I now have translation rules from LTL to UNITY so that, given an LTL property, part of the design of the system is choosing some elements of the corresponding UNITY properties. The big difference between UNITY and LTL is that UNITY properties are persistent but the LTL ones aren't. So what I do is that I associate a pair with each LTL property to make the UNITY properties based on the initial state.

The first element of the pair is a predicate that must hold initially and the second part is a set of (persistent) UNITY properties. As an example, consider <>p. This means that p is only required to hold once. It can hold more often or not. true ↦ p will be stronger but might also be too strong. Instead, we choose an initial predicate q and form the pair (q, q ↦ p) which means, initially q must hold and whenever it holds, p follows. It can be falsified early on or not. Either way works. Instead of q, we can choose a boolean variable b and decide its role in the design. Here are all the rules with p, q, r state predicates and X, Y LTL formulas, iX and iY their initial predicates and uX and uY their corresponding set of UNITY properties.

	LTL			relative UNITY (as opposed to persistent UNITY)
	p			(p, {})
	[] X			( iX, { invariant iX } ∪ uX )
	<> X		choose p in ( p, { p ↦ iX } ∪ uX )
	X W Y		choose p in ( p, { invariant p ⇒ iX , p ∧ ¬ iY un iY } ∪ uX ∪ uY )
		-- W implies no overlap
	X R Y		choose p in ( p, { invariant p ⇒ iY, p  un  iX ∧ p } ∪ uX ∪ uY )
		-- R has its arguments backward compared to W and implies an overlap
	X U Y		choose p in ( p, { invariant p ⇒ iX, p ↦ iY, p ∧ ¬ iY un iY } ∪ uX ∪ uY )
	X ∨ Y		( iX ∨ iY, uX ∪ uY )
	X ∧ Y		( iX ∧ iY, uX ∪ uY )
	¬ ( [] X )		see <> ¬ X
	¬ ( <> X )	see [] ¬ X
	¬ (X U Y)	see (¬ X) R (¬ Y)
	¬ (X R Y)	see (¬ X) U (¬ Y)
	¬ (X W Y)	¬ (X U Y ∨ []X)
				¬ (X U Y) ∧  ¬ [] X
				( (¬ X) R (¬ Y) ) ∧ <> ¬ X
				(¬ Y) U (¬ X ∧ ¬ Y)
	X ⇒ Y		see ¬ X ∨ Y
	X ≡ Y		see (X ⇒ Y) ∧ (Y ⇒ X)

In the case of []<>q, for the "eventually" part, we can choose the predicate p as true, which makes the invariant of "henceforth" trivial to prove. We land on { true ↦ q } as our set of UNITY properties

Proofs
	p  =  •p
	<>s  =  F ; s
	[] s  =  G s
	s U t  =  (μx :: (X;x ∧ s) ∨ t)
		-- if we had chosen the term (X;x ∨ t) ∧ s, we would force an 
		-- overlap between the last state where s holds and the first 
		-- where t holds
	s W t  =  (νx :: (X;x ∧ s) ∨ (s ∧ 1) ∨ t)
		-- the ∨ (s ∧ 1) is an addition after trying to prove (1)
		-- it covers the case of finite computations better
	s R t  =  (νx :: (X;x ∨ s ∨ 1) ∧ t)
		-- the ∨ 1 is an addition after trying to prove (0). 
		-- it covers the case of finite computations better

Healthiness checks
=================

(0)	¬(s U t) = (¬s) R (¬t)

		   ¬(s U t)
		=	{ unfold U }
		   ¬(μx :: (X;x ∧ s) ∨ t)
		=	{ dual }
		   (νx :: ¬( (X;¬x ∧ s) ∨ t ))
		=	{ ¬ over ∨ and  ∧ }
		   (νx :: (¬X;¬x ∨ ¬s) ∧ ¬t)
		=	{ RMD (41iii) }
		   (νx :: (X;x ∨ ¬s ∨ 1) ∧ ¬t)

If we use the above formulation as a new definition of R, it means that any finite computation can terminate without t happening. Let's see what other choice we have.

		   ¬(νx :: (X;x ∨ s) ∧ t)
		=	{ dual }
		   (μx :: ¬( (X;¬x ∨ s) ∧ t ))
		=	{ distribute ¬ }
		   (μx :: (¬X;¬x ∧ ¬s) ∨ ¬t)
		=	{ RMD (41iii) }
		   (μx :: ( (X;x ∨ 1) ∧ ¬s ) ∨ ¬t)
		=	{ ∧ over ∨ }
		   (μx :: ( (X;x ∧ ¬s) ∨ (1 ∧ ¬s) ) ∨ ¬t)

If we use the last step as a definition for U, it means that a computation can terminate before t becoming true. This would mean that [ s U t  ⇒  F;t ] does not hold which is not attractive at all. We will therefore use (νx :: (X;x ∨ ¬s ∨ 1) ∧ ¬t) as a definition of R instead.

(1)	s W t  =  s U t ∨ G s

We use fixpoint fusion (ref. (C15)) on

	(νx :: (X;x ∧ s) ∨ t)  =  sUt ∨ (νx :: (X;x ∨ 1) ∧ s)

with

	f.x  =  sUt  ∨  x
		(universally conjunctive)
	g.x  =  (X;x ∨ 1) ∧ s

According to our intuition of W, h should be as follows:

	h.x  =  (X;x ∧ s) ∨ t

We are left to prove

	f.(g.x) = h.(f.x)

Looking at the second part of the proof of (C15), we see that we will need something like (C18) to unfold sUt. Our initial guess is that the following will do. Let's try it.

	(2)	sUt  =  (s ∧ X ; (sUt)) ∨ t

		   f.(g.x)
		=	{ definitions }
		   sUt  ∨  ( (X;x ∨ 1) ∧ s )
		=	{ (2) }
		   t ∨ ( X;(sUt) ∧ s ) ∨ ( (X;x ∨ 1) ∧ s )
		=	{ ∧ over ∨ }
		   t ∨ (( X;(sUt) ∨ X;x ∨ 1 ) ∧ s)
		=	{ ; over ∨ }
		   t ∨ (( X;( (sUt) ∨ x ) ∨ 1 ) ∧ s)
		=	{ definition of f }
		   t ∨ (( X;( f.x ) ∨ 1 ) ∧ s)
		=	{ ∧ over ∨ }
		   t ∨ (X;( f.x ) ∧ s) ∨ (1 ∧ s)
		=	{ redefine h.x as (X;x ∧ s) ∨ (1 ∧ s) ∨ t }
		   h.( f.x )

	h.x  =  (X;x ∧ s) ∨ (1 ∧ s) ∨ t

(2)	p un q  =  G (•p  ⇒  •p W •q)

	we can prove the above by proving •p  ∧  •p W •q  =  (G •p) ; (X ∨ 1) ; •q

A first candidate for this proof is to use fixpoint fusion again. However, both fixpoints are present as subexpressions of their side of the equality.  Let's fix this by using (C4) on the right hand side of the equality to rewrite it  as:

	(νx :: (X;(x ∨ •q) ∨ •q) ∧ •p)

The fixpoint expression on the left hand side is:

	(νx :: (X;x ∧ •p) ∨ •q)

Then, we can consider the functions inside the fixpoints 

	f.x = X;x
	g.x = x ∧ •p
	h.x = x ∨ •q

and the two expressions are now

	P0:	ν( g ⚬ h ⚬ f ⚬ h )
and
	P1:	ν( h ⚬ g ⚬ f )

In order to calculate properly with them, here are a series of properties on how they interact pairwise.

	(0)	g ⚬ h  =  k ⚬ g
		with 
			k.x = x ∨ (•q ∧ •p)
	(1)	h ⚬ h  =  h
	(2)	g ⚬ g  =  g
	(3)	h ⚬ k  =  h

Let's try to make P0 appear by calculating with P1.

	   ν( h ⚬ g ⚬ f )		
	=	{ (3) }
	   ν( h ⚬ k ⚬ g ⚬ f )
	=	{ rolling }
	   h.( ν(k ⚬ g ⚬ f ⚬ h) )
	=	{ (0) }
	   h.( ν(g ⚬ h ⚬ f ⚬ h) )

Which gives us the equality 

		(νx :: (X;x ∧ •p) ∨ •q)  =  (νx :: (X;(x ∨ •q) ∨ •q) ∧ •p))  ∨  •q

Pretty interesting. What happens if we start calculating directly with P1 however? For the sake of increasing our freedom when manipulating h and g next to one another, let's see what we get when we rewrite h ⚬ g.

	(4)	h ⚬ g  =  t ⚬ h
		with
			t.x = x ∧ (•p ∨ •q)
	(5)	g ⚬ t = t ⚬ g = g

		   ν(g ⚬ h ⚬ f ⚬ h)
		=	{ rolling }
		   (g ⚬ h).( ν(f ⚬ h ⚬ g ⚬ h) )
		=	{ (4) }
		   (g ⚬ h).( ν(f ⚬ t ⚬ h ⚬ h) )
		=	{ (1) }
		   (g ⚬ h).( ν(f ⚬ t ⚬ h) )
		=	{ (4) }
		   (g ⚬ h).( ν(f ⚬ h ⚬ g) )
		=	{ (5), aiming to make g appear 
				to the right of h with (4) in
				order to enable "rolling" }
		   (g ⚬ t ⚬ h).( ν(f ⚬ h ⚬ g) )
		=	{ (4)  }
		   (g ⚬ h ⚬ g).( ν(f ⚬ h ⚬ g) )
		=	{ rolling }
		   g.( ν(h ⚬ g ⚬ f) )

This gives us the expected  result that

	(νx :: (X;(x ∨ •q) ∨ •q) ∧ •p)  =  •p ∧ (νx :: (X;x ∧ •p) ∨ •q)

		*						*
					*

In a previous attempt, we didn't realize that we needed to apply (5) then (4) before apply rolling last.  This gave us the surprising result that

	(νx :: (X;(x ∨ •q) ∨ •q) ∧ •p)  =  (νx :: (X;x ∧ •p) ∨ •q)

It is surprising because the left hand side implies •p but the right hand side does not seem to.  As a matter of fact, •q implies the right hand side and most definitely does not imply •p in general, which it would by transitivity if the above equality held.

Proof of [ •q ⇒ (νx :: (X;x ∧ •p) ∨ •q) ]

		   [ •q  ⇒  (νx :: (X;x ∧ •p) ∨ •q) ]
		⇐	{ induction }
		   [ •q  ⇒  (X;•q ∧ •p) ∨ •q ]
		=	{ weakening }
		   true

This set me to find an error in my last proof. How annoying ...
